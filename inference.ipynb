{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import torch\n",
    "import os, yaml\n",
    "from timm import create_model\n",
    "from data import create_dataset\n",
    "from models import MemSeg\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "def load_dataset(object_name):\n",
    "    global testset\n",
    "    testset = create_dataset(\n",
    "                        datadir                = cfg['DATASET']['datadir'],\n",
    "                        target                 = object_name, \n",
    "                        train                  = False,\n",
    "                        resize                 = cfg['DATASET']['resize'],\n",
    "                        texture_source_dir     = cfg['DATASET']['texture_source_dir'],\n",
    "                        structure_grid_size    = cfg['DATASET']['structure_grid_size'],\n",
    "                        transparency_range     = cfg['DATASET']['transparency_range'],\n",
    "                        perlin_scale           = cfg['DATASET']['perlin_scale'], \n",
    "                        min_perlin_scale       = cfg['DATASET']['min_perlin_scale'], \n",
    "                        perlin_noise_threshold = cfg['DATASET']['perlin_noise_threshold']\n",
    "                        )\n",
    "\n",
    "# Model\n",
    "def load_model(object_name, device='cpu'):\n",
    "    global model, cfg\n",
    "    cfg = yaml.load(open(f'./configs/{object_name.split(\"-\")[-1]}.yaml','r'), Loader=yaml.FullLoader)\n",
    "    memory_bank = torch.load(f'./saved_model/original/{object_name}/memory_bank.pt')\n",
    "    memory_bank.device = device\n",
    "    \n",
    "    for k in memory_bank.memory_information.keys():\n",
    "        memory_bank.memory_information[k] = memory_bank.memory_information[k].to(device)\n",
    "\n",
    "    encoder = encoder = create_model(cfg['MODEL']['feature_extractor_name'], \n",
    "                                    pretrained=True, \n",
    "                                    features_only = True\n",
    "                                    )\n",
    "    model = MemSeg(memory_module=memory_bank, encoder=encoder)\n",
    "    model.load_state_dict(torch.load(f'./saved_model/original/{object_name}/best_model.pt'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def minmax_scaling(img):\n",
    "    return (((img - img.min()) / (img.max() - img.min())) * 255).to(torch.uint8)\n",
    "\n",
    "def visualize_output(idx):\n",
    "    input_i, mask_i, target_i = testset[idx]\n",
    "\n",
    "    output_i = model(input_i.unsqueeze(0)).detach()\n",
    "    output_i = torch.nn.functional.softmax(output_i, dim=1)\n",
    "\n",
    "    fig, ax = plt.subplots(1,4, figsize=(15,10))\n",
    "    \n",
    "    ax[0].imshow(minmax_scaling(input_i.permute(1,2,0)))\n",
    "    ax[0].set_title('Input: {}'.format('Normal' if target_i == 0 else 'Abnormal'))\n",
    "    ax[1].imshow(mask_i, cmap='gray')\n",
    "    ax[1].set_title('Ground Truth')\n",
    "    ax[2].imshow(output_i[0][1], cmap='gray')\n",
    "    ax[2].set_title('Predicted Mask')\n",
    "    ax[3].imshow(minmax_scaling(input_i.permute(1,2,0)), alpha=1)\n",
    "    ax[3].imshow(output_i[0][1], cmap='gray', alpha=0.5)\n",
    "    ax[3].set_title(f'Input X Predicted Mask')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widgets\n",
    "\n",
    "model_list = widgets.Dropdown(\n",
    "    options=os.listdir('./saved_model/original/'),\n",
    "    value=f'MemSeg-Original-capsule',\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    ")\n",
    "model_button = widgets.Button(description=\"Select Model\")\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "@output.capture()\n",
    "def on_model_button_clicked(b):\n",
    "    clear_output(wait=True)\n",
    "    load_model(object_name=model_list.value)\n",
    "    load_dataset(object_name=model_list.value.split('-')[-1])\n",
    "    # vizualization\n",
    "    file_list = widgets.Dropdown(\n",
    "            options=[(file_path, i) for i, file_path in enumerate(testset.file_list)],\n",
    "            value=0,\n",
    "            description='image:',\n",
    "        )\n",
    "\n",
    "    widgets.interact(visualize_output, idx=file_list)\n",
    "\n",
    "model_button.on_click(on_model_button_clicked)\n",
    "display(widgets.HBox([model_list, model_button]), output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO RUN LOCAL HOST\n",
    "voila \"inference.ipynb\" --port 8866 --Voila.ip 127.0.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch-yolov7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e2e69c82a4eea91161427b303a6419fc60884bc14d10a93764a5f329cd55d5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
